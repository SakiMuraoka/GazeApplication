{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import japanize_matplotlib\n",
    "from sklearn import linear_model\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm,metrics\n",
    "from sklearn.metrics import confusion_matrix # 混合行列\n",
    "from sklearn.decomposition import PCA #主成分分析\n",
    "from sklearn.linear_model import LogisticRegression # ロジスティック回帰\n",
    "from sklearn.neighbors import KNeighborsClassifier # K近傍法\n",
    "from sklearn.svm import SVC # サポートベクターマシン\n",
    "from sklearn.tree import DecisionTreeClassifier # 決定木\n",
    "from sklearn.ensemble import RandomForestClassifier # ランダムフォレスト\n",
    "from sklearn.ensemble import AdaBoostClassifier # AdaBoost\n",
    "from sklearn.naive_bayes import GaussianNB # ナイーブ・ベイズ\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "# from sklearn.lda import LDA # 線形判別分析\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, r2_score, classification_report\n",
    "# from sklearn.qda import QDA # 二次判別分析\n",
    "from seglearn.pipe import Pype\n",
    "from seglearn.split import temporal_split\n",
    "from seglearn.transform import FeatureRep, SegmentX\n",
    "from seglearn.transform import SegmentXY, last, middle, mean\n",
    "from seglearn.feature_functions import all_features, minimum, maximum,  mean,  std, kurt, mean_diff, median, willison_amplitude, variation\n",
    "import math\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import random\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 瞬きの修正\n",
    "def blinkFix(data):\n",
    "    print(\"start blinkFix--------------\")\n",
    "    # 瞬き認識\n",
    "    blink = 0.7\n",
    "    blinkArray = []\n",
    "    for index, row in data.loc[data['eyeBlink'] > blink].iterrows():\n",
    "            blinkArray.append(index)\n",
    "   # 瞬きの始まりと終わり\n",
    "    blinkStartIndexs = []\n",
    "    blinkEndIndexs = []\n",
    "    for i in range(len(blinkArray)):\n",
    "        blinkStart = True\n",
    "        blinkEnd = True\n",
    "        if i - 1 >= 0:\n",
    "            if blinkArray[i] - 1 == blinkArray[i-1]:\n",
    "                blinkStart = False\n",
    "        if i + 1 < len(blinkArray):\n",
    "            if blinkArray[i] + 1 == blinkArray[i+1]:\n",
    "                blinkEnd = False       \n",
    "        if blinkStart:\n",
    "            blinkStartIndexs.append(i)\n",
    "        if blinkEnd:\n",
    "            blinkEndIndexs.append(i) \n",
    "    blink_data = data.copy()\n",
    "    startOffset = -5\n",
    "    endOffset = 15\n",
    "    for i in range(len(blinkStartIndexs)):\n",
    "        blinkStartIndex = blinkArray[blinkStartIndexs[i]]\n",
    "        blinkEndIndex = blinkArray[blinkEndIndexs[i]]\n",
    "        if blinkStartIndex+startOffset < 0:\n",
    "            blinkstart = 0\n",
    "        else:\n",
    "            blinkstart = blinkStartIndex+startOffset\n",
    "        \n",
    "        if blinkEndIndex+endOffset >= len(blink_data) :\n",
    "            blinkend = len(blink_data)-1\n",
    "        else:\n",
    "            blinkend = blinkEndIndex+endOffset\n",
    "        \n",
    "        for j in range(blinkstart, blinkend):\n",
    "            if j  >= 0 and  j < len(blink_data):\n",
    "                d = blinkstart-blinkend\n",
    "                ax = blink_data.iloc[blinkstart,:]['centerEyeLookAtPoint-x']-blink_data.iloc[blinkend,:]['centerEyeLookAtPoint-x']\n",
    "                bx = blinkstart*blink_data.iloc[blinkend,:]['centerEyeLookAtPoint-x'] - blinkend*blink_data.iloc[blinkstart,:]['centerEyeLookAtPoint-x']\n",
    "                ay = blink_data.iloc[blinkstart,:]['centerEyeLookAtPoint-y']-blink_data.iloc[blinkend,:]['centerEyeLookAtPoint-y']\n",
    "                by = blinkstart*blink_data.iloc[blinkend,:]['centerEyeLookAtPoint-y'] - blinkend*blink_data.iloc[blinkstart,:]['centerEyeLookAtPoint-y']\n",
    "                x = (ax*j + bx)/d\n",
    "                y = (ay*j + by )/d\n",
    "                blink_data.loc[blink_data.index == j, 'centerEyeLookAtPoint-x'] = x\n",
    "                blink_data.loc[blink_data.index == j, 'centerEyeLookAtPoint-y'] = y\n",
    "#      確認グラフ\n",
    "#     beforFix = data.iloc[blinkArray[blinkStartIndexs[5]]-15:blinkArray[blinkEndIndexs[5]]+25,:].copy()\n",
    "#     afterFix = blink_data.iloc[blinkArray[blinkStartIndexs[5]]-15:blinkArray[blinkEndIndexs[5]]+25,:].copy()\n",
    "#     from matplotlib import pyplot as plt\n",
    "#     plt1 = plt\n",
    "#     plt1.plot(beforFix.index, beforFix['centerEyeLookAtPoint-x'], label=\"beforFix\")\n",
    "#     plt1.plot(afterFix.index, afterFix['centerEyeLookAtPoint-x'], label=\"afterFix\")\n",
    "#     plt1.ylabel('centerEyeLookAtPoint-x')\n",
    "#     h1, l1 = plt1.axes().get_legend_handles_labels()\n",
    "#     plt2 = plt1.twinx()\n",
    "#     plt2.plot(afterFix.index, afterFix['eyeBlink'], c=\"r\", label=\"eyeBlink\", linestyle=\"dashed\")\n",
    "#     plt2.set_ylabel('eyeBlink')\n",
    "#     h2, l2 = plt2.get_legend_handles_labels()\n",
    "#     plt.legend(h1+h2, l1+l2, loc='upper left')\n",
    "#     print(type(plt2))\n",
    "#     plt1.show()\n",
    "    \n",
    "#     from matplotlib import pyplot as plt\n",
    "#     plt1 = plt\n",
    "#     plt1.plot(beforFix.index, beforFix['centerEyeLookAtPoint-y'], label=\"beforFix\")\n",
    "#     plt1.plot(afterFix.index, afterFix['centerEyeLookAtPoint-y'], label=\"afterFix\")\n",
    "#     plt1.ylabel('centerEyeLookAtPoint-y')\n",
    "#     h1, l1 = plt1.axes().get_legend_handles_labels()\n",
    "#     plt2 = plt1.twinx()\n",
    "#     plt2.plot(afterFix.index, afterFix['eyeBlink'], c=\"r\", label=\"eyeBlink\", linestyle=\"dashed\")\n",
    "#     plt2.set_ylabel('eyeBlink')\n",
    "#     h2, l2 = plt2.get_legend_handles_labels()\n",
    "#     plt.legend(h1+h2, l1+l2, loc='upper left')\n",
    "#     print(type(plt2))\n",
    "#     plt1.show()\n",
    "    \n",
    "    print(\"end blinkFix--------------\")\n",
    "    return blink_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataInit(data):\n",
    "    data['eyeBlink'] = (data['rightEyeBlink'] + data['leftEyeBlink'] )/2\n",
    "    data = data[['timestamp', 'centerEyeLookAtPoint-x', 'centerEyeLookAtPoint-y',  'eyeBlink', 'operationType', 'operationPoint-x', 'operationPoint-y']].copy()\n",
    "    print(\"start dataInit--------------\")\n",
    "    blink_data = blinkFix(data)\n",
    "    #キャリブレーション \n",
    "    target_x = blink_data.iloc[0,:]['operationPoint-x']\n",
    "    target_y = blink_data.iloc[0,:]['operationPoint-y']\n",
    "    for index, row in blink_data.iterrows():\n",
    "        if target_x != row['operationPoint-x'] or target_y != row['operationPoint-y']:\n",
    "            center_end = index-1\n",
    "            break\n",
    "    if center_end-150 < 0:\n",
    "        print(\"center_end-150<0\")\n",
    "    else:\n",
    "        center_start = center_end-150\n",
    "    eyePointMean_x= blink_data.iloc[center_start:center_end,:]['centerEyeLookAtPoint-x'].mean()\n",
    "    eyePointMean_y = blink_data.iloc[center_start: center_end,:]['centerEyeLookAtPoint-y'].mean()\n",
    "    cal_x = target_x - eyePointMean_x\n",
    "    cal_y = target_y - eyePointMean_y\n",
    "    blink_data['centerEyeLookAtPoint-x'] = blink_data['centerEyeLookAtPoint-x'] + cal_x \n",
    "    blink_data['centerEyeLookAtPoint-y'] = blink_data['centerEyeLookAtPoint-y'] + cal_y \n",
    "#     centerキャリブレーションの確かめグラフ\n",
    "#     cal_data = blink_data.iloc[center_start:center_end, :].copy()\n",
    "#     data_ = data.iloc[center_start:center_end,:].copy()\n",
    "#     plt.scatter(cal_data.index, cal_data['centerEyeLookAtPoint-y'], s=1, label=\"targetPoint-y(afterFix)\")\n",
    "#     plt.scatter(cal_data.index, cal_data['operationPoint-y'], s=1, label=\"operationPoint-x\")\n",
    "#     plt.scatter(data_.index, data_['centerEyeLookAtPoint-y'], s=1, label=\"targetPoint-y(beforFix)\")\n",
    "#     plt.xticks(rotation=40)\n",
    "#     plt.legend(loc=\"upper left\", fontsize=14) \n",
    "#     plt.show()\n",
    "    #分類に使用するデータ     \n",
    "    print(\"end dataInit--------------\")\n",
    "    return blink_data.iloc[center_end+1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画面をsplitx×splityに分割してカラム名columnにラベル付（0は例外）\n",
    "# data:ラベル付をするdataframe\n",
    "# column:ラベル付するカラム名\n",
    "# splitx,splity:画面を分割する数\n",
    "# shift:nextColumnをどれだけずらすか（プラス）\n",
    "def c_labeling(data, splitx, splity, shift):\n",
    "    print(\"start c_labeling--------------\")\n",
    "    column = 'area'\n",
    "    nextColumn = 'next_' + column\n",
    "    intention = 'switch'\n",
    "    width = 414\n",
    "    height = 896\n",
    "    x_d = width/splitx\n",
    "    y_d = height/splity\n",
    "    data[column] = 0\n",
    "    labelWidth = 5#ラベル付の幅\n",
    "    \n",
    "#     columnにラベル付\n",
    "    for index, row in data.iterrows():\n",
    "        if(row['operationPoint-x'] != 0 and row['operationPoint-y'] != 0):\n",
    "            label =  splitx * (math.floor(row['operationPoint-y']/y_d)) + math.floor(row['operationPoint-x']/x_d)+1\n",
    "            data.loc[data.index == index, column] = label\n",
    "    print(\"finish 1/3\")\n",
    "    \n",
    "#     nextColumnとintentionにラベル付\n",
    "    data[nextColumn] = 0\n",
    "    data[intention] = 0\n",
    "    for index, row in data.iterrows():\n",
    "        if index < len(data)-1:\n",
    "            if data.at[index, column] != data.at[index+1,column] and data.at[index+1, column] != 0:\n",
    "                if index-(shift-1) >= 0:\n",
    "                    data.at[index-(shift-1), nextColumn] = data.at[index+1, column]\n",
    "                for i in range(index-(shift-1)-(labelWidth-1), index+1-(shift-1)):\n",
    "                    if i >= 0:\n",
    "                        data.at[i, intention] = 1\n",
    "    print(\"finish 2/3\")\n",
    "\n",
    "    print(\"finish 3/3\")\n",
    "    print(\"end c_labeling--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# セグメンテーション，操作前を一定フレームごとに分割\n",
    "# width:何フレームでセグメントするか\n",
    "# segmentIx = []，segmentIy = []（操作直前か，そうでないかの分類用）（直前の場合）\n",
    "# segmentx = []，segmenty = []（操作直前の操作座標の全てのラベルの分類用）\n",
    "# intention:操作直前のラベル付がされたカラム名\n",
    "# nextColumn:操作座標のラベル付がされたカラム名\n",
    "# labelNum:操作座標が何分割されているか\n",
    "def segmentation(data, width, segmentIx, segmentIy, segmentx, segmenty):\n",
    "    print(\"start segmentation--------------\")\n",
    "    column = 'area'\n",
    "    nextColumn = 'next_' + column\n",
    "    intention = 'switch'\n",
    "    # segmentのwidth\n",
    "    shift = 5\n",
    "    for index, row in data.iterrows():\n",
    "        if index >= width-1and index < len(data)-1:\n",
    "            data_ = data.iloc[index-(width-1):index+1,:].copy()\n",
    "            segmentIx.append(data_[['centerEyeLookAtPoint-x', 'centerEyeLookAtPoint-y']].values)\n",
    "            segmentIy.append(row[intention])\n",
    "            if row[nextColumn] != 0:\n",
    "                for i in range(index-shift-1, index+1):\n",
    "                    data_ = data.iloc[i-(width-1): i+1,:].copy()\n",
    "                    segmentx.append(data_[['centerEyeLookAtPoint-x', 'centerEyeLookAtPoint-y']].values)\n",
    "                    segmenty.append(row[nextColumn])\n",
    "    print(len(segmentx))     \n",
    "    print(\"end segmentation--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# セグメントのラベル数を揃える\n",
    "def adjust_cLabel(segmentIx, segmentIy, segmentx, segmenty):\n",
    "    print(\"start adjust_segment--------------\")\n",
    "    onelist = [i for i, x in enumerate(segmentIy) if x == 1]\n",
    "    zerolist = [j for j, y in enumerate(segmentIy) if y == 0]\n",
    "    random.shuffle(zerolist)\n",
    "    dI = len(zerolist)-len(onelist)\n",
    "    print(\"onelist: {0}, zerolist: {1}, dI: {2}\".format(len(onelist), len(zerolist), dI))\n",
    "    zerolist_ = zerolist[:dI]\n",
    "    print(\"zerolist_:{0}\".format(len(zerolist_)))\n",
    "    for k in sorted(zerolist_, reverse=True):\n",
    "        segmentIy.pop(k)\n",
    "        segmentIx.pop(k)\n",
    "    print(\"finish 1/2\")           \n",
    "    print(\"min:{0}, max:{1}\".format(min(segmenty), max(segmenty)))\n",
    "    countlist = {}\n",
    "    for i in range(len(segmenty)):\n",
    "        if segmenty[i] in countlist:\n",
    "            countlist[segmenty[i]] += 1\n",
    "        else:\n",
    "            countlist[segmenty[i]] = 1\n",
    "        \n",
    "    countmin = countlist[min(countlist)]\n",
    "    print(countmin) \n",
    "    for key, val in countlist.items():\n",
    "        if val > countmin:\n",
    "            print(\"key:{0}, val:{1}\".format(key, val))\n",
    "            indexlist = [m for m, z in enumerate(segmenty) if z == key]\n",
    "            random.shuffle(indexlist)\n",
    "            d = countlist[key] - countmin\n",
    "            indexlist_ = indexlist[:d]\n",
    "            for n in sorted(indexlist_, reverse=True):\n",
    "                segmenty.pop(n)\n",
    "                segmentx.pop(n)\n",
    "    print(\"finish 2/2\")\n",
    "    print(\"end adjust_segment--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(clf, segmentx, segmenty):\n",
    "    y, y_p = clf.transform_predict(segmentx, segmenty)\n",
    "    labels = sorted(list(set(y)))\n",
    "    cm_ = confusion_matrix(y,  y_p, labels=labels)\n",
    "    cm = cm_.astype(np.float32)\n",
    "    for i in range(len(cm)):\n",
    "        sum = 0\n",
    "        for j in range(len(cm[0])):\n",
    "            sum += cm[i][j]\n",
    "        cm[i] = (cm[i]*100)/sum\n",
    "#     cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    sns.heatmap(cm, cmap='Blues', annot=True, fmt='.1f', vmin=0, vmax=100)\n",
    "    plt.xlabel('予測ラベル')\n",
    "    plt.ylabel('正解ラベル')\n",
    "    plt.tight_layout()\n",
    "    plt.rcParams[\"font.size\"] = 10\n",
    "    plt.rcParams['figure.figsize'] = (7.0, 6.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "# fts：特徴量（配列）\n",
    "# classifer：モデル\n",
    "# labelCount：1つのラベルの数\n",
    "def classification(fts, classifier, segmentIx, segmentIy):\n",
    "    clf = Pype([\n",
    "                    ('features', FeatureRep(features=fts)),  # extracts features\n",
    "                    ('rf', classifier)  #  ML algorithm of sklearn\n",
    "                ])\n",
    "\n",
    "    print(clf)\n",
    "    segmentIx = np.array(segmentIx)\n",
    "    X = segmentIx\n",
    "    Y = segmentIy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "    print(\"count of data:\", len(segmentIx))\n",
    "\n",
    "    # # fit and score\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"score of test data：\", score)\n",
    "    score = clf.score(X_train, y_train)\n",
    "    print(\"score of train data：\", score)\n",
    "    score = clf.score(X, Y)\n",
    "    print(\"score of all data：\", score)\n",
    "    \n",
    "    heatmap(clf, X_test, y_test)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_(clf, segmentx, segmenty):\n",
    "    score= clf.score(segmentx, segmenty)\n",
    "    print(\"count of data：{0}\".format(len(segmentx)))\n",
    "    print(\"clf_score: {0}\".format(score))\n",
    "    heatmap(clf, segmentx, segmenty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ftsScore(fts_name, fts_name_, fts_, classifier, segmentIx, segmentIy):\n",
    "    segmentIx = np.array(segmentIx)\n",
    "    X = segmentIx\n",
    "    Y = segmentIy\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=0)\n",
    "    result = []\n",
    "    for i in range(len(fts_name)):\n",
    "        fts = {fts_name[i]: fts_[i]}\n",
    "        clf = Pype([\n",
    "                        ('features', FeatureRep(features=fts)),  # extracts features\n",
    "                        ('rf', RandomForestClassifier(n_estimators=20))  #  ML algorithm of sklearn\n",
    "                    ])\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        score1 = clf.score(X_train, y_train)\n",
    "        score2 = clf.score(X_test, y_test)\n",
    "        result.append([score1, score2])\n",
    "    df_result = pd.DataFrame(result, columns=['train', 'test'], index=fts_name_).sort_values('test', ascending=False)\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    df_result.plot(kind='bar', alpha=0.5, grid=True)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, y1, x2, y2):\n",
    "    disx = x1-x2\n",
    "    disy = y1-y2\n",
    "    dis = np.sqrt(disx**2 + disy**2)\n",
    "    return dis\n",
    "# 視線と操作座標の距離の確認用\n",
    "def distSeg(data, width, segment, column):\n",
    "    # segmentのwidth\n",
    "    shift = width\n",
    "    opeDist = 0\n",
    "    for index, row in data.iterrows():\n",
    "        if index < len(data)-1 and index > shift:\n",
    "            if row[column] != data.iloc[index+1,:][column] and data.iloc[index+1,:][column] != 0:\n",
    "                #next columnを追加\n",
    "                data_ = data.loc[index-(shift-2):index+1,:].copy()\n",
    "                dist = distance(data_['centerEyeLookAtPoint-x'], data.iloc[index+1,:]['operationPoint-x'], data_['centerEyeLookAtPoint-y'], data.iloc[index+1,:]['operationPoint-y'])  \n",
    "                data_['distance'] = dist\n",
    "                data_['opeDistance'] = 0\n",
    "                for index_, row_ in data_.iterrows():\n",
    "                    if not(row_['operationPoint-x'] == 0 and row_['operationPoint-y'] == 0):\n",
    "                        opeDist = distance(data_.at[index_, 'operationPoint-x'], data.iloc[index+1,:]['operationPoint-x'], data_.at[index_, 'operationPoint-y'], data.iloc[index+1,:]['operationPoint-y'])             \n",
    "                    data_.at[index_, 'opeDistance'] = opeDist\n",
    "                data_['nextOpePoint-x'] = data.iloc[index+1,:]['operationPoint-x']\n",
    "                data_['nextOpePoint-y'] = data.iloc[index+1,:]['operationPoint-y']\n",
    "                segment.append(data_[['centerEyeLookAtPoint-x', 'centerEyeLookAtPoint-y', 'operationPoint-x', 'operationPoint-y', 'distance', 'opeDistance', \n",
    "                                      'nextOpePoint-x', 'nextOpePoint-y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ平滑化\n",
    "def dataRolling(data, window):\n",
    "    data['centerEyeLookAtPoint-y'] = data['centerEyeLookAtPoint-y'].rolling(window=window, min_periods=1).mean()\n",
    "    data['centerEyeLookAtPoint-x'] = data['centerEyeLookAtPoint-x'].rolling(window=window, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction(data):\n",
    "    # segmentのwidth\n",
    "    shift = width\n",
    "    sx = data.iloc[0,:]['operationPoint-x']\n",
    "    sy = data.iloc[0,:]['operationPoint-y']\n",
    "    data['direction_ope'] = 0\n",
    "    data['direction_eye'] = 0\n",
    "    for index, row in data.iterrows():\n",
    "        if index < len(data)-2:\n",
    "            dire_ope = math.atan2(sy-data.iloc[index+1,:]['operationPoint-y'], sx-data.iloc[index+1,:]['operationPoint-x'])\n",
    "            dire_eye = math.atan2(row['centerEyeLookAtPoint-y']-data.iloc[index+1,:]['centerEyeLookAtPoint-y'], row['centerEyeLookAtPoint-x']-data.iloc[index+1,:]['centerEyeLookAtPoint-x'])\n",
    "            data.at[index, 'direction_ope'] = math.degrees(dire_ope)\n",
    "            data.at[index, 'direction_eye'] = math.degrees(dire_eye)\n",
    "            sx = row['centerEyeLookAtPoint-x']\n",
    "            sy = row['centerEyeLookAtPoint-y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの事前処理\n",
    "# mode：セグメントモード(0：学習時，1：予測時)\n",
    "# csv_data_s：csvデータ(dataframe)の配列\n",
    "# column：操作座標ラベルのカラム名\n",
    "# splitx，splity：画面分割数\n",
    "# shift：ラベルをずらす数\n",
    "# width：セグメントの幅\n",
    "def pre_processing(mode, csv_datas, segmentIx, segmentIy, segmentx, segmenty, splitx, splity, shift, width):\n",
    "    data = pd.DataFrame(index=[])\n",
    "    for csv_data in csv_datas:\n",
    "        data_ = dataInit(csv_data)\n",
    "        dataRolling(data_, 30)\n",
    "        c_labeling(data_, splitx, splity, shift)\n",
    "        segmentation(data_, width, segmentIx, segmentIy, segmentx, segmenty)\n",
    "        data = pd.concat([data, data_])\n",
    "    data = data.reset_index(drop=True)\n",
    "    if mode == 0:\n",
    "        adjust_cLabel(segmentIx, segmentIy, segmentx, segmenty)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# データ処理\n",
    "csv_data1_ = pd.read_csv('./csvFile/saki/saki_2020121207440260200_home.csv')\n",
    "csv_data2_ = pd.read_csv('./csvFile/saki/saki_2020121208154033100_home.csv')\n",
    "csv_data3_ = pd.read_csv('./csvFile/saki/saki_2020121213360798900_home.csv')\n",
    "csv_data4_ = pd.read_csv('./csvFile/saki/saki_2020121807340371200_home.csv')\n",
    "csv_data5_ = pd.read_csv('./csvFile/saki/saki_2020121816101633100_home.csv')\n",
    "csv_data6_ = pd.read_csv('./csvFile/saki/saki_2020122007312691200_home.csv')\n",
    "# 学習用データ\n",
    "# csv_datas = [csv_data1_, csv_data2_, csv_data3_, csv_data4_, csv_data5_]\n",
    "# segIx4_0 = []\n",
    "# segIy4_0 = []\n",
    "# segx4_0 = []\n",
    "# segy4_0 = []\n",
    "# data4_0 = pre_processing(0, csv_datas, segIx4_0, segIy4_0, segx4_0, segy4_0, 2, 2, 0, 150)\n",
    "# # 確かめデータ\n",
    "# csv_datas_ = [csv_data6_]\n",
    "# segIx4_0_ = []\n",
    "# segIy4_0_ = []\n",
    "# segx4_0_ = []\n",
    "# segy4_0_ = []\n",
    "# data4_0_ = pre_processing(1, csv_datas_, segIx4_0_, segIy4_0_, segx4_0_, segy4_0_, 2, 2, 0, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start dataInit--------------\n",
      "start blinkFix--------------\n",
      "end blinkFix--------------\n",
      "end dataInit--------------\n",
      "start c_labeling--------------\n",
      "finish 1/3\n",
      "finish 2/3\n",
      "finish 3/3\n",
      "end c_labeling--------------\n",
      "start segmentation--------------\n",
      "1442\n",
      "end segmentation--------------\n",
      "start dataInit--------------\n",
      "start blinkFix--------------\n",
      "end blinkFix--------------\n",
      "end dataInit--------------\n",
      "start c_labeling--------------\n",
      "finish 1/3\n",
      "finish 2/3\n",
      "finish 3/3\n",
      "end c_labeling--------------\n",
      "start segmentation--------------\n",
      "3045\n",
      "end segmentation--------------\n",
      "start dataInit--------------\n",
      "start blinkFix--------------\n",
      "end blinkFix--------------\n",
      "end dataInit--------------\n",
      "start c_labeling--------------\n",
      "finish 1/3\n",
      "finish 2/3\n",
      "finish 3/3\n",
      "end c_labeling--------------\n",
      "start segmentation--------------\n",
      "4515\n",
      "end segmentation--------------\n",
      "start dataInit--------------\n",
      "start blinkFix--------------\n",
      "end blinkFix--------------\n",
      "end dataInit--------------\n",
      "start c_labeling--------------\n",
      "finish 1/3\n",
      "finish 2/3\n",
      "finish 3/3\n",
      "end c_labeling--------------\n",
      "start segmentation--------------\n",
      "5929\n",
      "end segmentation--------------\n",
      "start dataInit--------------\n",
      "start blinkFix--------------\n",
      "end blinkFix--------------\n",
      "end dataInit--------------\n",
      "start c_labeling--------------\n",
      "finish 1/3\n",
      "finish 2/3\n",
      "finish 3/3\n",
      "end c_labeling--------------\n",
      "start segmentation--------------\n",
      "7343\n",
      "end segmentation--------------\n",
      "start adjust_segment--------------\n",
      "onelist: 5217, zerolist: 45861, dI: 40644\n",
      "zerolist_:40644\n",
      "finish 1/2\n",
      "min:1, max:4\n",
      "1540\n",
      "key:2, val:1617\n",
      "key:3, val:1960\n",
      "key:4, val:2198\n",
      "finish 2/2\n",
      "end adjust_segment--------------\n",
      "start dataInit--------------\n",
      "start blinkFix--------------\n",
      "end blinkFix--------------\n",
      "end dataInit--------------\n",
      "start c_labeling--------------\n",
      "finish 1/3\n",
      "finish 2/3\n",
      "finish 3/3\n",
      "end c_labeling--------------\n",
      "start segmentation--------------\n",
      "1484\n",
      "end segmentation--------------\n"
     ]
    }
   ],
   "source": [
    "csv_datas = [csv_data1_, csv_data2_, csv_data3_, csv_data4_, csv_data5_]\n",
    "segIx4_60 = []\n",
    "segIy4_60 = []\n",
    "segx4_60 = []\n",
    "segy4_60 = []\n",
    "data4_60 = pre_processing(0, csv_datas, segIx4_60, segIy4_60, segx4_60, segy4_60, 2, 2, 60, 150)\n",
    "# 確かめデータ\n",
    "csv_datas_ = [csv_data6_]\n",
    "segIx4_60_ = []\n",
    "segIy4_60_ = []\n",
    "segx4_60_ = []\n",
    "segy4_60_ = []\n",
    "data4_60_ = pre_processing(1, csv_datas_, segIx4_60_, segIy4_60_, segx4_60_, segy4_60_, 2, 2, 60, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>centerEyeLookAtPoint-x</th>\n",
       "      <th>centerEyeLookAtPoint-y</th>\n",
       "      <th>eyeBlink</th>\n",
       "      <th>operationType</th>\n",
       "      <th>operationPoint-x</th>\n",
       "      <th>operationPoint-y</th>\n",
       "      <th>area</th>\n",
       "      <th>next_area</th>\n",
       "      <th>switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41870</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41871</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41872</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41873</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41874</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  centerEyeLookAtPoint-x  centerEyeLookAtPoint-y  eyeBlink  \\\n",
       "41870        NaN                     NaN                     NaN       NaN   \n",
       "41871        NaN                     NaN                     NaN       NaN   \n",
       "41872        NaN                     NaN                     NaN       NaN   \n",
       "41873        NaN                     NaN                     NaN       NaN   \n",
       "41874        NaN                     NaN                     NaN       NaN   \n",
       "\n",
       "      operationType  operationPoint-x  operationPoint-y  area  next_area  \\\n",
       "41870           NaN               NaN               NaN   NaN        2.0   \n",
       "41871           NaN               NaN               NaN   NaN        NaN   \n",
       "41872           NaN               NaN               NaN   NaN        NaN   \n",
       "41873           NaN               NaN               NaN   NaN        NaN   \n",
       "41874           NaN               NaN               NaN   NaN        NaN   \n",
       "\n",
       "       switch  \n",
       "41870     1.0  \n",
       "41871     1.0  \n",
       "41872     1.0  \n",
       "41873     1.0  \n",
       "41874     1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexlist = [m for m, z in enumerate(segy4_60) if z == 'NaN']\n",
    "# print(len(indexlist))\n",
    "# print(segy4_60[indexlist[0]])\n",
    "# data4_60[data4_60['next_area'].isnull()]\n",
    "data4_60[data4_60['area'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41870\n",
      "41871\n",
      "41872\n",
      "41873\n",
      "41874\n"
     ]
    }
   ],
   "source": [
    "for index, row in data4_60.iterrows():\n",
    "    if row['next_area'] != 0:\n",
    "        if row['next_area'] != data4_60.iloc[index+60, :]['area']:\n",
    "            print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_get_value() missing 1 required positional argument: 'col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9e93244c2b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata4_60\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m41869\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m41870\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata4_60\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/envs/test/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _get_value() missing 1 required positional argument: 'col'"
     ]
    }
   ],
   "source": [
    "data4_60.iloc[41869:41870,:]\n",
    "data4_60.at[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_datas = [csv_data1_, csv_data2_, csv_data3_, csv_data4_, csv_data5_]\n",
    "segIx4_300 = []\n",
    "segIy4_300 = []\n",
    "segx4_300 = []\n",
    "segy4_300 = []\n",
    "data4_300 = pre_processing(0, csv_datas, segIx4_300, segIy4_300, segx4_300, segy4_300, 2, 2, 300, 150)\n",
    "# 確かめデータ\n",
    "csv_datas_ = [csv_data6_]\n",
    "segIx4_300_ = []\n",
    "segIy4_300_ = []\n",
    "segx4_300_ = []\n",
    "segy4_300_ = []\n",
    "data4_300_ = pre_processing(1, csv_datas_, segIx4_300_, segIy4_300_, segx4_300_, segy4_300_, 2, 2, 300, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_datas = [csv_data1_, csv_data2_, csv_data3_, csv_data4_, csv_data5_]\n",
    "segIx28_0 = []\n",
    "segIy28_0 = []\n",
    "segx28_0 = []\n",
    "segy28_0 = []\n",
    "data28_0 = pre_processing(0, csv_datas, segIx28_0, segIy28_0, segx28_0, segy28_0, 4, 7, 0, 150)\n",
    "# 確かめデータ\n",
    "csv_datas_ = [csv_data6_]\n",
    "segIx28_0_ = []\n",
    "segIy28_0_ = []\n",
    "segx28_0_ = []\n",
    "segy28_0_ = []\n",
    "data28_0_ = pre_processing(1, csv_datas_, segIx28_0_, segIy28_0_, segx28_0_, segy28_0_, 4, 7, 0, 150)\n",
    "csv_datas = [csv_data1_, csv_data2_, csv_data3_, csv_data4_, csv_data5_]\n",
    "segIx28_60 = []\n",
    "segIy28_60 = []\n",
    "segx28_60 = []\n",
    "segy28_60 = []\n",
    "data28_60 = pre_processing(0, csv_datas, segIx28_60, segIy28_60, segx28_60, segy28_60, 4, 7, 60, 150)\n",
    "# 確かめデータ\n",
    "csv_datas_ = [csv_data6_]\n",
    "segIx28_60_ = []\n",
    "segIy28_60_ = []\n",
    "segx28_60_ = []\n",
    "segy28_60_ = []\n",
    "data28_60_ = pre_processing(1, csv_datas_, segIx28_60_, segIy28_60_, segx28_60_, segy28_60_, 4, 7, 60, 150)\n",
    "csv_datas = [csv_data1_, csv_data2_, csv_data3_, csv_data4_, csv_data5_]\n",
    "segIx28_300 = []\n",
    "segIy28_300 = []\n",
    "segx28_300 = []\n",
    "segy28_300 = []\n",
    "data28_300 = pre_processing(0, csv_datas, segIx28_300, segIy28_300, segx28_300, segy28_300, 4, 7, 300, 150)\n",
    "# 確かめデータ\n",
    "csv_datas_ = [csv_data6_]\n",
    "segIx28_300_ = []\n",
    "segIy28_300_ = []\n",
    "segx28_300_ = []\n",
    "segy28_300_ = []\n",
    "data28_300_ = pre_processing(1, csv_datas_, segIx28_300_, segIy28_300_, segx28_300_, segy28_300_, 4, 7, 300, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作直前かそうでないかの分類\n",
    "print(\"操作直前\")\n",
    "fts = {'var': variation, 'std': std, 'med': median}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clfI4_0 = classification(fts, classifier, segIx4_0, segIy4_0)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clfI4_0.sav'\n",
    "pickle.dump(clfI4_0, open(filename, 'wb'))\n",
    "\n",
    "# 操作座標の分類\n",
    "print(\"操作領域\")\n",
    "fts = {'mean': mean, 'med': median, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clf4_0 = classification(fts, classifier, segx4_0, segy4_0)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clf4_0.sav'\n",
    "pickle.dump(clf4_0, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"確認4_0\")\n",
    "classification_(clfI4_0, segIx4_0_, segIy4_0_)\n",
    "classification_(clf4_0, segx4_0_, segy4_0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作直前かそうでないかの分類\n",
    "print(\"操作直前\")\n",
    "fts = {'var': variation, 'std': std, 'med': median}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clfI4_60 = classification(fts, classifier, segIx4_60, segIy4_60)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clfI4_60.sav'\n",
    "pickle.dump(clfI4_60, open(filename, 'wb'))\n",
    "\n",
    "# 操作座標の分類\n",
    "print(\"操作領域\")\n",
    "fts = {'mean': mean, 'med': median, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clf4_60 = classification(fts, classifier, segx4_60, segy4_60)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clf4_60.sav'\n",
    "pickle.dump(clf4_60, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"確認4_60\")\n",
    "classification_(clfI4_60, segIx4_0_, segIy4_60_)\n",
    "classification_(clf4_60, segx4_60_, segy4_60_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作直前かそうでないかの分類\n",
    "print(\"操作直前\")\n",
    "fts = {'var': variation, 'std': std, 'med': median}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clfI4_300 = classification(fts, classifier, segIx4_300, segIy4_300)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clfI4_300.sav'\n",
    "pickle.dump(clfI4_300, open(filename, 'wb'))\n",
    "\n",
    "# 操作座標の分類\n",
    "print(\"操作領域\")\n",
    "fts = {'mean': mean, 'med': median, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clf4_300 = classification(fts, classifier, segx4_300, segy4_300)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clf4_300.sav'\n",
    "pickle.dump(clf4_300, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"確認4_300\")\n",
    "classification_(clfI4_300, segIx4_300_, segIy4_300_)\n",
    "classification_(clf4_300, segx4_300_, segy4_300_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作直前かそうでないかの分類\n",
    "print(\"操作直前\")\n",
    "fts = {'var': variation, 'std': std, 'med': median}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clfI28_0 = classification(fts, classifier, segIx28_0, segIy28_0)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clfI28_0.sav'\n",
    "pickle.dump(clfI28_0, open(filename, 'wb'))\n",
    "\n",
    "# 操作座標の分類\n",
    "print(\"操作領域\")\n",
    "fts = {'mean': mean, 'med': median, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clf28_0 = classification(fts, classifier, segx28_0, segy28_0)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clf28_0.sav'\n",
    "pickle.dump(clf28_0, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"確認28_0\")\n",
    "scoreI = clfI28_0.score(segIx28_0_, segIy28_0_)\n",
    "print(\"count of data：{0}\".format(len(segIx28_0_)))\n",
    "print(\"clfI28_0score: {0}\".format(scoreI))\n",
    "heatmap(clfI28_0, segIx28_0_, segIy28_0_)\n",
    "score = clfI28_0.score(segx28_0_, segy28_0_)\n",
    "print(\"count of data：{0}\".format(len(segx28_0_)))\n",
    "print(\"clf28_0score: {0}\".format(score))\n",
    "heatmap(clf28_0, segx28_0_, segy28_0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作直前かそうでないかの分類\n",
    "print(\"操作直前\")\n",
    "fts = {'var': variation, 'std': std, 'med': median}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clfI28_60 = classification(fts, classifier, segIx28_60, segIy28_60)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clfI28_60.sav'\n",
    "pickle.dump(clfI28_60, open(filename, 'wb'))\n",
    "\n",
    "# 操作座標の分類\n",
    "print(\"操作領域\")\n",
    "fts = {'mean': mean, 'med': median, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clf28_60 = classification(fts, classifier, segx28_60, segy28_60)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clf28_60.sav'\n",
    "pickle.dump(clf28_60, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作直前かそうでないかの分類\n",
    "print(\"操作直前\")\n",
    "fts = {'var': variation, 'std': std, 'med': median}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clfI28_300 = classification(fts, classifier, segIx28_300, segIy28_300)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clfI28_300.sav'\n",
    "pickle.dump(clfI28_300, open(filename, 'wb'))\n",
    "\n",
    "# 操作座標の分類\n",
    "print(\"操作領域\")\n",
    "fts = {'mean': mean, 'med': median, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clf28_300 = classification(fts, classifier, segx28_300, segy28_300)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clf28_300.sav'\n",
    "pickle.dump(clf28_300, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cal_data = data.iloc[156:256, :].copy()\n",
    "# plt.scatter(cal_data.index, cal_data['centerEyeLookAtPoint-y'], s=1, label=\"targetPoint-y\")\n",
    "# plt.scatter(cal_data.index, cal_data['operationPoint-y'], s=1, label=\"operationPoint-y\")\n",
    "# plt.xticks(rotation=40)\n",
    "# # plt.legend(loc=\"upper left\", fontsize=14) \n",
    "# plt.show()\n",
    "# data1.iloc[204:250,:]\n",
    "print(len([j for j, x in enumerate(segIy1) if x == 0]))\n",
    "print(len([i for i, x in enumerate(segIy1) if x == 1]))\n",
    "# print(len(segIx1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.iloc[195:240,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.iloc[32500:32550,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.iloc[430:440,:]\n",
    "demoData = data1.copy()\n",
    "dis_seg = []\n",
    "width = 400\n",
    "distSeg(demoData, width, dis_seg, 'area')\n",
    "pltSeg = dis_seg[10]\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(range(width), pltSeg['distance'],label=\"distance(nop-ce)\")\n",
    "plt.plot(range(width), pltSeg['opeDistance'], label=\"distance(nop-cop)\")\n",
    "plt.xticks(rotation=40)\n",
    "plt.legend(loc=\"upper left\", fontsize=14) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demoData = data1.copy()\n",
    "dataRolling(demoData, 30)\n",
    "dis_seg = []\n",
    "width = 400\n",
    "distSeg(demoData, width, dis_seg, 'area')\n",
    "pltSeg = dis_seg[10]\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(range(width), pltSeg['distance'],label=\"distance(nop-ce)\")\n",
    "plt.plot(range(width), pltSeg['opeDistance'], label=\"distance(nop-cop)\")\n",
    "plt.xticks(rotation=40)\n",
    "plt.legend(loc=\"upper left\", fontsize=14) \n",
    "plt.show()\n",
    "\n",
    "# pltSeg = dis_seg[100]\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.scatter(range(width), pltSeg['distance'], s=1, label=\"distance\")\n",
    "# plt.scatter(range(width), pltSeg['opeDistance'], s=1, label=\"opeDistance\")\n",
    "# plt.xticks(rotation=40)\n",
    "# plt.legend(loc=\"upper left\", fontsize=14) \n",
    "# plt.show()\n",
    "\n",
    "# pltSeg = dis_seg[700]\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.scatter(range(width), pltSeg['distance'], s=1, label=\"distance\")\n",
    "# plt.scatter(range(width), pltSeg['opeDistance'], s=1, label=\"opeDistance\")\n",
    "# plt.xticks(rotation=40)\n",
    "# plt.legend(loc=\"upper left\", fontsize=14) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directionData = data1.copy()\n",
    "direction(directionData)\n",
    "s = 10\n",
    "width = 300\n",
    "pltSeg = directionData.iloc[s: s+width, :]\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(pltSeg.index, pltSeg['direction_ope'], label=\"direction(op)\")\n",
    "plt.plot(pltSeg.index+1, pltSeg['direction_eye'],  label=\"direction(eye)\")\n",
    "plt.xticks(rotation=40)\n",
    "plt.legend(loc=\"upper left\", fontsize=14) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視線と操作位置の距離\n",
    "# directionData = data1.copy()\n",
    "# dataRolling(directionData, 20)\n",
    "# direction(directionData)\n",
    "s = 100\n",
    "width = 300\n",
    "pltSeg = directionData.iloc[s: s+width, :]\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(pltSeg.index, pltSeg['direction_ope'], label=\"direction(op)\")\n",
    "plt.plot(pltSeg.index+1, pltSeg['direction_eye'],  label=\"direction(eye)\")\n",
    "plt.xticks(rotation=40)\n",
    "plt.legend(loc=\"upper left\", fontsize=14) \n",
    "plt.show()\n",
    "\n",
    "# s = 100\n",
    "# pltSeg = directionData.iloc[s: s+width, :]\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.plot(pltSeg.index, pltSeg['direction_ope'], label=\"direction_ope\")\n",
    "# plt.plot(pltSeg.index+1, pltSeg['direction_eye'],  label=\"direction_eye\")\n",
    "# plt.xticks(rotation=40)\n",
    "# plt.legend(loc=\"upper left\", fontsize=14) \n",
    "# plt.show()\n",
    "\n",
    "# s = 1000\n",
    "# pltSeg = directionData.iloc[s: s+width, :]\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.plot(pltSeg.index, pltSeg['direction_ope'], label=\"direction_ope\")\n",
    "# plt.plot(pltSeg.index+1, pltSeg['direction_eye'],  label=\"direction_eye\")\n",
    "# plt.xticks(rotation=40)\n",
    "# plt.legend(loc=\"upper left\", fontsize=14) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平滑化の確認\n",
    "a = directionData.iloc[100:300]\n",
    "b = data1.iloc[100:300]\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(a.index, a['centerEyeLookAtPoint-x'], label=\"after\")\n",
    "plt.plot(b.index, b['centerEyeLookAtPoint-x'], label=\"befor\")\n",
    "plt.xticks(rotation=40)\n",
    "plt.legend(loc=\"upper left\", fontsize=14) \n",
    "plt.show()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(a.index, a['centerEyeLookAtPoint-y'], label=\"after\")\n",
    "plt.plot(b.index, b['centerEyeLookAtPoint-y'], label=\"befor\")\n",
    "plt.xticks(rotation=40)\n",
    "plt.legend(loc=\"upper left\", fontsize=14) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pypeのsegmentxyを使う場合（テストデータとトレインデータの分割でラベルの数を合わせられない）\n",
    "# one_count = 0\n",
    "# shift = 150\n",
    "# for index, row in data.iterrows():\n",
    "#     if row['intention'] == 1 and index-shift > 0:\n",
    "#         one_count += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pypeのsegmentxyを使う場合（テストデータとトレインデータの分割でラベルの数を合わせられない）\n",
    "# count = 0\n",
    "# data_ = pd.DataFrame()\n",
    "# for index, row in data.iterrows():\n",
    "#     if index-shift+1 >= 0:\n",
    "#         if row['intention'] == 0 and count < one_count:\n",
    "#             count += 1\n",
    "#             data_ = data_.append(data.iloc[index-shift+1: index+1, :])\n",
    "#         elif row['intention'] == 1:\n",
    "#             data_ = data_.append(data.iloc[index-shift+1: index+1, :])\n",
    "# data_ = data_.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pypeのsegmentxyを使う場合（ラベルの数を揃えて分割できなくてダメ）\n",
    "# x = data_[['centerEyeLookAtPoint-x', 'centerEyeLookAtPoint-y']].values\n",
    "# y = data_['nextClass'].values\n",
    "# y = data_['intention'].values\n",
    "# X = [x]\n",
    "# Y = [y]\n",
    "# X, Y, _ = seg_xy.transform(xs, ys)\n",
    "# X_train, X_test, y_train, y_test = temporal_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#いろんな分類器を比較\n",
    "# names = [\"Logistic Regression\", \"Nearest Neighbors\", \n",
    "#          \"Linear SVM\", \"Polynomial SVM\", \"RBF SVM\", \"Sigmoid SVM\", \n",
    "#          \"Decision Tree\",\"Random Forest\", \"AdaBoost\", \"Naive Bayes\", \n",
    "#          \"Linear Discriminant Analysis\",\"Quadratic Discriminant Analysis\"]\n",
    "\n",
    "# classifiers = [\n",
    "#     LogisticRegression(),\n",
    "#     KNeighborsClassifier(),\n",
    "#     SVC(kernel=\"linear\"),\n",
    "#     SVC(kernel=\"poly\"),\n",
    "#     SVC(kernel=\"rbf\"),\n",
    "#     SVC(kernel=\"sigmoid\"),\n",
    "#     DecisionTreeClassifier(),\n",
    "#     RandomForestClassifier(),\n",
    "#     AdaBoostClassifier(),\n",
    "#     GaussianNB(),\n",
    "#     LDA(),\n",
    "#     QDA()]\n",
    "# result = []\n",
    "# for name, clf in zip(names, classifiers): # 指定した複数の分類機を順番に呼び出す\n",
    "#     clf = Pype([\n",
    "#                 ('features', FeatureRep(features=all_features())),  # extracts features\n",
    "#                 ('rf', clf)  #  ML algorithm of sklearn\n",
    "#             ])\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     score1 = clf.score(X_train, y_train) # 正解率（train）の算出\n",
    "#     score2 = clf.score(X_test, y_test) # 正解率（test）の算出\n",
    "#     result.append([score1, score2]) # 結果の格納\n",
    "\n",
    "# # test の正解率の大きい順に並べる\n",
    "# df_result = pd.DataFrame(result, columns=['train', 'test'], index=names).sort_values('test', ascending=False)\n",
    "# df_result # 結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result.plot(kind='bar', alpha=0.5, grid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = clf.predict(X_test)\n",
    "# cm = confusion_matrix(y_test, pred)\n",
    "# sns.heatmap(cm)\n",
    "# plt.tight_layout()\n",
    "# plt.rcParams['figure.figsize'] = (20.0, 20.0)\n",
    "# plt.show()\n",
    "\n",
    "# create a pipeline\n",
    "# clf = Pype([\n",
    "#                 ('segment', SegmentXY(width=150, overlap=0, y_func=last)),  # segmentation\n",
    "#                 ('features', FeatureRep()),  # extracts features\n",
    "#                 ('rf', RandomForestClassifier(n_estimators=20))  #  ML algorithm of sklearn\n",
    "#             ])\n",
    " \n",
    "# print(clf)\n",
    "# print(segmenty1)\n",
    "# print(len([j for j, x in enumerate(segmenty2) if x == 28]))\n",
    "# print(len([i for i, x in enumerate(segmenty2) if x == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 操作直前かそうでないかの分類\n",
    "fts = {'var': variation, 'std': std, 'med': median}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clfI1 = calssification(fts, classifier, segIx1, segIy1)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clfI1.sav'\n",
    "pickle.dump(clfI1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作座標の分類\n",
    "fts = {'mean': mean, 'med': median, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clf1 = calssification(fts, classifier, segx1, segy1)\n",
    "# モデルを保存する\n",
    "filename = './model/home_clf1.sav'\n",
    "pickle.dump(clf1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(segy))\n",
    "scoreI = clfI1.score(segIx1_, segIy1_)\n",
    "print(\"count of data：{0}\".format(len(segIx1_)))\n",
    "print(\"clfI1_score: {0}\".format(scoreI))\n",
    "heatmap(clfI1, segIx1_, segIy1_)\n",
    "score = clfI1.score(segx1_, segy1_)\n",
    "print(\"count of data：{0}\".format(len(segx1_)))\n",
    "print(\"clf1_score: {0}\".format(score))\n",
    "heatmap(clf1, segx1_, segy1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量ごとのスコア（操作直前かそうでないかの分類）\n",
    "fts_name = ['min', 'max', 'mean', 'std', 'kurt', 'meand', 'med', 'var']\n",
    "fts_name_ = ['最小値', '最大値', '平均', '標準偏差', '尖度',  '平均時間微分', '中央値', '変動係数']\n",
    "fts_ = [minimum, maximum, mean, std, kurt, mean_diff, median, variation]\n",
    "ftsScore(fts_name, fts_name_, fts_, classifier, segIx4_0, segIy4_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量ごとのスコア（操作座標の分類）\n",
    "fts_name = ['min', 'max', 'mean', 'std', 'kurt', 'meand', 'med', 'var']\n",
    "fts_name_ = ['最小値', '最大値', '平均', '標準偏差', '尖度',  '平均時間微分', '中央値', '変動係数']\n",
    "fts_ = [minimum, maximum, mean, std, kurt, mean_diff, median, variation]\n",
    "ftsScore(fts_name, fts_name_, fts_, classifier, segx4_0, segy4_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = {'min': minimum, 'max': maximum, 'med': median}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clfI2 = calssification(fts, classifier, segIx2, segIy2)\n",
    "filename = './model/home_clfI2.sav'\n",
    "pickle.dump(clfI2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fts_name = ['min', 'max', 'mean', 'std', 'kurt', 'meand', 'med', 'var']\n",
    "# fts_name_ = ['最小値', '最大値', '平均', '標準偏差', '尖度',  '平均時間微分', '中央値', '変動係数']\n",
    "# fts_ = [minimum, maximum, mean, std, kurt, mean_diff, median, variation]\n",
    "# ftsScore(fts_name, fts_name_, fts_, classifier, segx2, segy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = {'min': minimum, 'max': maximum, 'med': median}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clf2 = calssification(fts, classifier, segx2, segy2)\n",
    "filename = './model/home_clf2.sav'\n",
    "pickle.dump(clf2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreI = clfI2.score(segIx2_, segIy2_)\n",
    "print(\"count of data：{0}\".format(len(segIx2_)))\n",
    "print(\"clfI2_score: {0}\".format(scoreI))\n",
    "heatmap(clfI2, segIx2_, segIy2_)\n",
    "print(\"count of data：{0}\".format(len(segx2_)))\n",
    "print(\"clf2_score: {0}\".format(score))\n",
    "scoreI = clf2.score(segx2_, segy2_)\n",
    "heatmap(clf2, segx2_, segy2_)\n",
    "\n",
    "\n",
    "# max_score = 0\n",
    "# SearchMethod = 0\n",
    "# RFC_grid = {RandomForestClassifier(): {\"n_estimators\": [i for i in range(1, 21)],\n",
    "#                                        \"criterion\": [\"gini\", \"entropy\"],\n",
    "#                                        \"max_depth\":[i for i in range(1, 5)],\n",
    "#                                        \"random_state\": [i for i in range(0, 101)]\n",
    "#                                       }}\n",
    "\n",
    "# #ランダムフォレストの実行\n",
    "# for model, param in tqdm(RFC_grid.items()):\n",
    "#     clf = Pype([\n",
    "#                 ('features', FeatureRep(features=all_features())),  # extracts features\n",
    "#                 ('rf', GridSearchCV(model, param))  #  ML algorithm of sklearn\n",
    "#             ])\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     pred_y = clf.predict(X_test)\n",
    "#     score = f1_score(y_test, pred_y, average=\"micro\")\n",
    "\n",
    "#     if max_score < score:\n",
    "#         max_score = score\n",
    "#         best_param = clf.get_params\n",
    "#         best_model = model\n",
    "\n",
    "# print(\"ベストスコア:{}\".format(max_score))\n",
    "# print(\"モデル:{}\".format(best_model))\n",
    "# print(\"パラメーター:{}\".format(best_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間かかる\n",
    "# clf = Pype([\n",
    "#                 ('segment', SegmentXY(width=200, overlap=0.8, y_func=last)),  # segmentation\n",
    "#                 ('features', FeatureRep()),  # extracts features\n",
    "#                 ('rf', classifiers[2])  #  ML algorithm of sklearn\n",
    "#             ])\n",
    "\n",
    "# # fit and score\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# score = clf.score(X_test, y_test)\n",
    "# print(\"score of test data：\", score)\n",
    "# score = clf.score(X_train, y_train)\n",
    "# print(\"score of train data：\", score)\n",
    "\n",
    "# score = clf.score(segmentx, segmenty)\n",
    "# print(\"score of all data：\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.iloc[60,:]['timestamp'] - data.iloc[0,:]['timestamp']\n",
    "# print(data.iloc[0:10,:])\n",
    "# 約1秒ずらし\n",
    "demoIx = []\n",
    "demoIy = []\n",
    "demox = []\n",
    "demoy = []\n",
    "pre_processing(0, csv_datas, 'Class_demo', demoIx, demoIy, demox,  demoy, 2, 2, 60, 150)\n",
    "fts = {'meand': mean_diff, 'mean': mean, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "calssification(fts, classifier, demoIx, demoIy)\n",
    "calssification(fts, classifier, demox, demoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.iloc[300,:]['timestamp'] - data.iloc[0,:]['timestamp']\n",
    "# 約5秒ずらし\n",
    "demoIx2 = []\n",
    "demoIy2 = []\n",
    "demox2 = []\n",
    "demoy2 = []\n",
    "pre_processing(0, csv_datas, 'Class_demo2', demoIx2, demoIy2, demox2,  demoy2, 2, 2, 300, 150)\n",
    "fts = {'meand': mean_diff, 'mean': mean, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "calssification(fts, classifier, demoIx2, demoIy2)\n",
    "calssification(fts, classifier, demox2, demoy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo.iloc[480:500, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.iloc[500,:]['timestamp'] - data.iloc[0,:]['timestamp']\n",
    "# 約10秒ずらし\n",
    "demoIx3 = []\n",
    "demoIy3 = []\n",
    "demox3 = []\n",
    "demoy3 = []\n",
    "pre_processing(0, csv_datas, 'Class_demo3', demoIx3, demoIy3, demox3,  demoy3, 2, 2, 500, 150)\n",
    "fts = {'meand': mean_diff, 'mean': mean, 'var': variation}\n",
    "classifier = RandomForestClassifier(n_estimators=20)\n",
    "clf = calssification(fts, classifier, demoIx3, demoIy3)\n",
    "clf = calssification(fts, classifier, demox3, demoy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demoseg_ = demo.iloc[340:490].copy()\n",
    "# demoseg = demoseg_[['centerEyeLookAtPoint-x', 'centerEyeLookAtPoint-y']].values\n",
    "# # demo_p = clf.predict(demoseg)\n",
    "# demoseg\n",
    "# print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
